<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Welcome</title>
    <link rel="stylesheet" href="css/index.css">
    <link rel="stylesheet" href="css/global.css">
    <link rel="stylesheet" href="css/welcome.css">
    <link rel="icon" href="/static/logo.png" type="image/x-icon" />
</head>

<body>
    <div id="loader-container"></div>
    <div class="welcome-container" style="display:none;">
        <!-- <h1 class="onboarding-heading">Onboarding</h1> -->
        <div class="onboarding-subtext" id="welcome-text"></div>
        <div class="onboarding-instruction"></div>
        <div id="startButtonDiv">
            <button id="startButton" class="start-btn" onclick="init()">Start</button>
        </div>
        <div id="status" class="status"></div>
        <div id="error" class="error"></div>
    </div>
    <div id="audioVisualizer" hidden>
        <div>
            <h1 class="onboarding-heading">Onboarding</h1>
        </div>
        <div>
            <button id="stopButton" onclick="stopRecording()">Stop</button>
        </div>
        <canvas id="waveform"></canvas>
        <canvas id="waveform2"></canvas>
    </div>
</body>
<script src="js/welcome.js"></script>
<script>
    const startButton = document.getElementById('startButton');
    const stopButton = document.getElementById('stopButton');
    const transcriptDiv = document.getElementById('transcript');
    const statusDiv = document.getElementById('status');
    const errorDiv = document.getElementById('error');

    let peerConnection = null;
    let audioStream = null;
    let dataChannel = null;

    // Message handling functions
    function handleTranscript(message) {
        if (message.response?.output?.[0]?.content?.[0]?.transcript) {
            transcriptDiv.textContent += message.response.output[0].content[0].transcript + ' ';
        }
    }

    async function handleWeatherFunction(output) {
        try {
            const args = JSON.parse(output.arguments);
            const location = args.location;

            const response = await fetch(`http://localhost:8888/weather/${encodeURIComponent(location)}`);
            const data = await response.json();

            // Send function output
            sendFunctionOutput(output.call_id, {
                temperature: data.temperature,
                unit: data.unit,
                location: location
            });

            // Request new response
            sendResponseCreate();
        } catch (error) {
            showError('Error handling weather function: ' + error.message);
        }
    }

    function handleFunctionCall(output) {
        if (output?.type === "function_call" &&
            output?.name === "get_weather" &&
            output?.call_id) {
            console.log('Function call found:', output);
            handleWeatherFunction(output);
        }
    }

    function handleMessage(event) {
        try {
            const message = JSON.parse(event.data);
            // console.log('Received message:', message);
            console.log("message type is: ", message.type)
            switch (message.type) {
                case "response.done":
                    handleTranscript(message);
                    const output = message.response?.output?.[0];

                    // This is called when AI wants Fx mostly
                    if (output) {

                        handleFunctionCall(output)
                    };
                    break;

                // If text only then this prints the text
                case "response.text.delta":
                    console.log("the message is: ", message)
                    console.log(message.delta)
                    break;
                // This code gives you entire response at once if only text modality.
                // if (message.response?.output?.[0]?.content?.[0]?.text) {
                //         // Log the text response
                //         const textResponse = message.response.output[0].content[0].text;
                //         console.log("OpenAI Text Response:", textResponse);
                //     }
                default:
                // console.log('Unhandled message type:', message.type);
            }
        } catch (error) {
            showError('Error processing message: ' + error.message);
        }
    }

    // WebRTC setup functions
    async function setupAudio() {
        const audioEl = document.createElement("audio");
        audioEl.autoplay = true;
        peerConnection.ontrack = (e) => {
            audioEl.srcObject = e.streams[0]; // Plays system audio
            processAudioForVisualization(e.streams[0]); // Process system audio
        };

        audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        peerConnection.addTrack(audioStream.getTracks()[0]);
        console.log("audioStream=>", audioStream)
    }

    function setupDataChannel() {
        dataChannel = peerConnection.createDataChannel("oai-events");
        dataChannel.onopen = onDataChannelOpen;
        dataChannel.addEventListener("message", handleMessage);
    }

    // Message sending functions
    function sendSessionUpdate() {
        const sessionUpdateEvent = {
            "type": "session.update",
            "session": {
                "tools": [{
                    "type": "function",
                    "name": "get_weather",
                    "description": "Get the current weather. Works only for Earth",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location": { "type": "string" }
                        },
                        "required": ["location"]
                    }
                }],
                "tool_choice": "auto",
                "modalities": ["audio", "text"]
                // "modalities": ["text"]
            }
        };
        sendMessage(sessionUpdateEvent);
    }

    function sendInitialMessage() {
        const conversationMessage = {
            "type": "conversation.item.create",
            "previous_item_id": null,
            "item": {
                "id": "msg_" + Date.now(),
                "type": "message",
                "role": "user",
                "content": [{
                    "type": "input_text",
                    "text": "My name is Geert and I live in Antwerp, Belgium."
                }]
            }
        };
        sendMessage(conversationMessage);
    }

    function sendFunctionOutput(callId, data) {
        const responseMessage = {
            "type": "conversation.item.create",
            "item": {
                "type": "function_call_output",
                "call_id": callId,
                "output": JSON.stringify(data)
            }
        };
        sendMessage(responseMessage);
    }

    function sendResponseCreate() {
        sendMessage({ "type": "response.create" });
    }

    function sendMessage(message) {
        if (dataChannel?.readyState === "open") {
            dataChannel.send(JSON.stringify(message));
            console.log('Sent message:', message);
            
            document.getElementById("audioVisualizer").style.display = "block";
        }
    }

    function onDataChannelOpen() {
        sendSessionUpdate();
        sendInitialMessage();
    }

    // Main control functions
    async function init() {
        startButton.disabled = true;
        try {
            updateStatus('Initializing...');

            const tokenResponse = await fetch("https://aef9dd6d-fb52-456e-9e21-f5e2f54be901-00-2e96ef993fwys.kirk.replit.dev/session/");
            const data = await tokenResponse.json();
            const EPHEMERAL_KEY = data.client_secret.value;

            peerConnection = new RTCPeerConnection();
            await setupAudio();
            setupDataChannel();

            const offer = await peerConnection.createOffer();
            await peerConnection.setLocalDescription(offer);

            const baseUrl = "https://api.openai.com/v1/realtime";
            const model = "gpt-4o-realtime-preview-2024-12-17";
            const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
                method: "POST",
                body: offer.sdp,
                headers: {
                    Authorization: `Bearer ${EPHEMERAL_KEY}`,
                    "Content-Type": "application/sdp"
                },
            });

            const answer = {
                type: "answer",
                sdp: await sdpResponse.text(),
            };
            await peerConnection.setRemoteDescription(answer);

            updateStatus('Connected');
            document.querySelector(".welcome-container").style.display = "none";
            startMic();


            // window.location.href = '/public/audioVisualizer.html';
            stopButton.disabled = false;
            hideError();

        } catch (error) {
            startButton.disabled = false;
            stopButton.disabled = true;
            showError('Error: ' + error.message);
            console.error('Initialization error:', error);
            updateStatus('Failed to connect');
        }
    }

    function stopRecording() {
        if (peerConnection) {
            peerConnection.close();
            peerConnection = null;
        }
        if (audioStream) {
            audioStream.getTracks().forEach(track => track.stop());
            audioStream = null;
        }
        if (dataChannel) {
            dataChannel.close();
            dataChannel = null;
        }
        startButton.disabled = false;
        stopButton.disabled = true;
        // updateStatus('Ready to start');
        updateStatus('');
        document.querySelector(".welcome-container").style.display = "flex";
        document.getElementById("audioVisualizer").style.display = "none";
        hideError();
    }

    // UI helper functions
    function updateStatus(message) {
        statusDiv.textContent = message;
    }

    function showError(message) {
        errorDiv.style.display = 'block';
        errorDiv.textContent = message;
    }

    function hideError() {
        errorDiv.style.display = 'none';
    }



    let audioContext, analyserMic, analyserServer;
let microphone, serverAudio;
let dataArrayMic, dataArrayServer;
let canvasMic, canvasServer, canvasCtxMic, canvasCtxServer;

// ðŸŽ¤ Start Microphone Visualization
function startMic() {
    navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }

            analyserMic = audioContext.createAnalyser();
            analyserMic.fftSize = 512;

            microphone = audioContext.createMediaStreamSource(stream);
            microphone.connect(analyserMic);

            const bufferLength = analyserMic.frequencyBinCount;
            dataArrayMic = new Uint8Array(bufferLength);

            canvasMic = document.getElementById("waveform");
            canvasCtxMic = canvasMic.getContext("2d");

            setupCanvas(canvasMic);
            drawWaveMic();
        })
        .catch(error => console.error("Microphone access denied:", error));
}

let ripples = [];

function drawWaveMic() {
    requestAnimationFrame(drawWaveMic);
    analyserMic.getByteTimeDomainData(dataArrayMic);

    let volume = dataArrayMic.reduce((a, b) => a + b, 0) / dataArrayMic.length; // Get avg volume

    // Add ripple if volume is high enough
    if (volume > 130) { 
        ripples.push({
            x: canvasMic.width / 2,
            y: canvasMic.height / 2, // Start from the center
            radius: 5, // Small initial ripple
            opacity: 1, // Fully visible
            speed: Math.random() * 2 + 1 
        });
    }

    // **Apply Fading Effect Instead of Full Clear**
    canvasCtxMic.fillStyle = "#f7f7e8"; 
    canvasCtxMic.fillRect(0, 0, canvasMic.width, canvasMic.height);

    // **Draw & Animate Ripples**
    for (let i = 0; i < ripples.length; i++) {
        let ripple = ripples[i];
        ripple.radius += ripple.speed; // Expand
        ripple.opacity -= 0.02; // Fade out
        ripple.y += 0.2; // Small gravity effect

        if (ripple.opacity <= 0) {
            ripples.splice(i, 1); // Remove faded ripples
            i--;
            continue;
        }

        canvasCtxMic.beginPath();
        canvasCtxMic.arc(ripple.x, ripple.y, ripple.radius, 0, Math.PI * 2);
        canvasCtxMic.strokeStyle = `rgba(50, 205, 50, ${ripple.opacity})`; // Limegreen fade
        canvasCtxMic.lineWidth = 2;
        canvasCtxMic.stroke();
    }
}


// ðŸŽ¶ Draw Server Waveform
function drawWaveServer() {
    requestAnimationFrame(drawWaveServer);
    analyserServer.getByteTimeDomainData(dataArrayServer);

    canvasCtxServer.fillStyle = "#f7f7e8";
    canvasCtxServer.fillRect(0, 0, canvasServer.width, canvasServer.height);

    canvasCtxServer.lineWidth = 2;
    canvasCtxServer.strokeStyle = "cyan";
    canvasCtxServer.beginPath();

    let sliceWidth = canvasServer.width / dataArrayServer.length;
    let x = 0;

    for (let i = 0; i < dataArrayServer.length; i++) {
        let v = dataArrayServer[i] / 128.0;
        let y = v * canvasServer.height / 2;

        if (i === 0) {
            canvasCtxServer.moveTo(x, y);
        } else {
            canvasCtxServer.lineTo(x, y);
        }
        x += sliceWidth;
    }

    canvasCtxServer.lineTo(canvasServer.width, canvasServer.height / 2);
    canvasCtxServer.stroke();
}
    function drawWave() {
        requestAnimationFrame(drawWave);
        analyser.getByteTimeDomainData(dataArray);

        canvasCtx.fillStyle = "#f4f4f4";
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

        canvasCtx.lineWidth = 2;
        canvasCtx.strokeStyle = "limegreen";
        canvasCtx.beginPath();

        let sliceWidth = canvas.width / dataArray.length;
        let x = 0;

        for (let i = 0; i < dataArray.length; i++) {
            let v = dataArray[i] / 128.0;
            let y = v * canvas.height / 2;

            if (i === 0) {
                canvasCtx.moveTo(x, y);
            } else {
                canvasCtx.lineTo(x, y);
            }
            x += sliceWidth;
        }

        canvasCtx.lineTo(canvas.width, canvas.height / 2);
        canvasCtx.stroke();
    }

// ðŸ“¡ Process Server Audio Stream (WebRTC)
function processAudioForVisualization(stream) {
    if (!audioContext) {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
    }

    analyserServer = audioContext.createAnalyser();
    analyserServer.fftSize = 512;

    serverAudio = audioContext.createMediaStreamSource(stream);
    serverAudio.connect(analyserServer);

    const bufferLength = analyserServer.frequencyBinCount;
    dataArrayServer = new Uint8Array(bufferLength);

    canvasServer = document.getElementById("waveform2");
    canvasCtxServer = canvasServer.getContext("2d");

    setupCanvas(canvasServer);
    drawWaveServer();
}

    function setupCanvas() {
        const container = document.getElementById("audioVisualizer");
        container.style.display = "block"; // Ensure it's visible

        // setTimeout(() => {
        //     canvas.width = canvas.clientWidth || 800;
        //     canvas.height = canvas.clientHeight || 300;
        // }, 100);
    }
</script>

</html>